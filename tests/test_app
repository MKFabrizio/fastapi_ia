import pytest
from fastapi.testclient import TestClient

# ---------- Test 1: unit test generate_text with a fake pipe ----------
def test_generate_text_with_fake_pipe(monkeypatch):
    from models import generate_text  # uses your real function

    class FakeTokenizer:
        def apply_chat_template(self, messages, tokenize=False, add_generation_prompt=True):
            # return any prompt-like string; generate_text just passes it to the pipe
            return "PROMPT"

    class FakePipe:
        def __init__(self):
            self.tokenizer = FakeTokenizer()
        def __call__(self, prompt, temperature, max_new_tokens, do_sample, top_k, top_p):
            # Mimic HF pipeline output shape
            return [{"generated_text": "ignored</s>\n<|assistant|>\nHello world!"}]

    out = generate_text(FakePipe(), "any question")
    assert "Hello" in out

# ---------- Test 2: FastAPI endpoint happy-path (mock model + generation) ----------
def test_api_generate_text_success(monkeypatch):
    import main  # imports your FastAPI app

    # Avoid loading the real model
    monkeypatch.setattr(main, "load_text_model", lambda: object())

    def fake_generate_text(pipe, prompt):
        return f"Echo: {prompt}"
    monkeypatch.setattr(main, "generate_text", fake_generate_text)

    client = TestClient(main.app)
    r = client.get("/generate/text", params={"prompt": "hi"})
    assert r.status_code == 200
    assert r.json() == "Echo: hi"  # FastAPI returns JSON string when you return str

# ---------- Test 3: FastAPI validation (prompt required) ----------
def test_api_requires_prompt():
    import main
    client = TestClient(main.app)
    r = client.get("/generate/text")  # no 'prompt' query param
    assert r.status_code == 422  # Unprocessable Entity due to missing required parameter
